"""
–£–ú–ù–´–ô –ü–û–ò–°–ö –ö–û–ù–¢–ê–ö–¢–û–í –° –ü–†–ò–û–†–ò–¢–ò–ó–ê–¶–ò–ï–ô
–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º API (1000 –∑–∞–ø—Ä–æ—Å–æ–≤ 2GIS)
"""

import json
import csv
import time
import requests
from typing import Dict, List, Optional, Tuple
from pathlib import Path
from datetime import datetime
from collections import Counter


class SmartContactsFinder:
    """–£–º–Ω—ã–π –ø–æ–∏—Å–∫ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ —Å –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏–µ–π –∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏"""
    
    def __init__(self, api_key_2gis: str, cache_file: str = "contacts_cache.json"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É–º–Ω–æ–≥–æ –ø–æ–∏—Å–∫–æ–≤–∏–∫–∞
        
        Args:
            api_key_2gis: API –∫–ª—é—á 2GIS
            cache_file: –§–∞–π–ª –¥–ª—è –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        """
        self.api_key_2gis = api_key_2gis
        self.base_url_2gis = "https://catalog.api.2gis.com/3.0/items"
        self.cache_file = cache_file
        self.cache = self._load_cache()
        self.request_delay = 0.5
        self.api_calls_count = 0
        self.api_limit = 1000  # –õ–∏–º–∏—Ç –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        
    def _load_cache(self) -> Dict:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –∫–µ—à –∏–∑ —Ñ–∞–π–ª–∞"""
        try:
            if Path(self.cache_file).exists():
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–µ—à–∞: {e}")
        return {}
    
    def _save_cache(self):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–µ—à –≤ —Ñ–∞–π–ª"""
        try:
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–µ—à–∞: {e}")
    
    def analyze_vacancies(self, json_file: str) -> Tuple[List[Dict], Dict]:
        """
        –ê–Ω–∞–ª–∏–∑ –≤–∞–∫–∞–Ω—Å–∏–π –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ –∫–æ–º–ø–∞–Ω–∏–π
        
        Args:
            json_file: –ü—É—Ç—å –∫ JSON —Ñ–∞–π–ª—É —Å –≤–∞–∫–∞–Ω—Å–∏—è–º–∏
            
        Returns:
            Tuple[List[Dict], Dict]: (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∫–æ–º–ø–∞–Ω–∏–π, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞)
        """
        print("üìä –ê–Ω–∞–ª–∏–∑ –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏–∏...")
        
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                vacancies = json.load(f)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
            return [], {}
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–∫–∞–Ω—Å–∏–π –ø–æ –∫–æ–º–ø–∞–Ω–∏—è–º
        company_vacancies = {}
        company_details = {}
        
        for vacancy in vacancies:
            company = vacancy.get('–∫–æ–º–ø–∞–Ω–∏—è', '').strip()
            if not company:
                continue
            
            if company not in company_vacancies:
                company_vacancies[company] = []
                company_details[company] = {
                    'vacancies_count': 0,
                    'has_salary': False,
                    'avg_salary': 0,
                    'sample_vacancy': vacancy.get('–Ω–∞–∑–≤–∞–Ω–∏–µ', '')
                }
            
            company_vacancies[company].append(vacancy)
            company_details[company]['vacancies_count'] += 1
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∑–∞—Ä–ø–ª–∞—Ç—ã
            salary = vacancy.get('–æ–ø–ª–∞—Ç–∞', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')
            if salary != '–ù–µ —É–∫–∞–∑–∞–Ω–∞' and '—Ä—É–±' in salary:
                company_details[company]['has_salary'] = True
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–π —Å–ø–∏—Å–æ–∫
        prioritized = []
        for company, details in company_details.items():
            priority_score = details['vacancies_count']
            
            # –ë–æ–Ω—É—Å –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—É—é –∑–∞—Ä–ø–ª–∞—Ç—É (–±–æ–ª–µ–µ —Å–µ—Ä—å–µ–∑–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏)
            if details['has_salary']:
                priority_score *= 1.5
            
            prioritized.append({
                'company': company,
                'vacancies_count': details['vacancies_count'],
                'has_salary': details['has_salary'],
                'sample_vacancy': details['sample_vacancy'],
                'priority_score': priority_score
            })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
        prioritized.sort(key=lambda x: x['priority_score'], reverse=True)
        
        stats = {
            'total_vacancies': len(vacancies),
            'total_companies': len(prioritized),
            'companies_with_salary': len([c for c in prioritized if c['has_salary']]),
            'top_10_companies': prioritized[:10]
        }
        
        return prioritized, stats
    
    def search_company_2gis(self, company_name: str, city: str = "–ú–æ—Å–∫–≤–∞") -> Optional[Dict]:
        """
        –ü–æ–∏—Å–∫ –∫–æ–º–ø–∞–Ω–∏–∏ –≤ 2GIS
        
        Args:
            company_name: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏
            city: –ì–æ—Ä–æ–¥ –ø–æ–∏—Å–∫–∞
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∫–æ–Ω—Ç–∞–∫—Ç–∞–º–∏ –∏–ª–∏ None
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à
        cache_key = f"2gis_{company_name}_{city}"
        if cache_key in self.cache:
            return self.cache[cache_key]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç
        if self.api_calls_count >= self.api_limit:
            print(f"‚ö†Ô∏è –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç API 2GIS ({self.api_limit} –∑–∞–ø—Ä–æ—Å–æ–≤)")
            return None
        
        # –î–µ–ª–∞–µ–º –∑–∞–ø—Ä–æ—Å –∫ API
        try:
            params = {
                'q': company_name,
                'key': self.api_key_2gis,
                'locale': 'ru_RU',
                'fields': 'items.contact_groups,items.address,items.org',
                'region_id': self._get_region_id(city)
            }
            
            response = requests.get(self.base_url_2gis, params=params, timeout=10)
            self.api_calls_count += 1
            
            if response.status_code == 200:
                data = response.json()
                
                if data.get('result') and data['result'].get('items'):
                    item = data['result']['items'][0]
                    contacts = self._extract_contacts_2gis(item, company_name)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–µ—à
                    self.cache[cache_key] = contacts
                    self._save_cache()
                    
                    time.sleep(self.request_delay)
                    return contacts
                else:
                    result = {
                        'company_name': company_name,
                        'found': False,
                        'source': '2gis',
                        'search_date': datetime.now().isoformat()
                    }
                    self.cache[cache_key] = result
                    self._save_cache()
                    return result
            else:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ API 2GIS: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ 2GIS: {e}")
            return None
        finally:
            time.sleep(self.request_delay)
    
    def search_company_alternative(self, company_name: str, vacancy_link: str = None) -> Optional[Dict]:
        """
        –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ (–ø–∞—Ä—Å–∏–Ω–≥ HH.ru)
        
        Args:
            company_name: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏
            vacancy_link: –°—Å—ã–ª–∫–∞ –Ω–∞ –≤–∞–∫–∞–Ω—Å–∏—é (–º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–Ω—Ç–∞–∫—Ç—ã)
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ –∫–æ–Ω—Ç–∞–∫—Ç–∞–º–∏ –∏–ª–∏ None
        """
        cache_key = f"alt_{company_name}"
        if cache_key in self.cache:
            return self.cache[cache_key]
        
        contacts = {
            'company_name': company_name,
            'found': False,
            'source': 'alternative',
            'search_date': datetime.now().isoformat(),
            'phones': [],
            'emails': [],
            'websites': []
        }
        
        # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∫–æ–Ω—Ç–∞–∫—Ç—ã –∏–∑ HH.ru (–∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è –∫–æ–º–ø–∞–Ω–∏–∏)
        if vacancy_link:
            try:
                # –ü–æ–ª—É—á–∞–µ–º ID –≤–∞–∫–∞–Ω—Å–∏–∏
                vacancy_id = vacancy_link.split('/')[-1]
                
                # –ó–∞–ø—Ä–æ—Å –∫ API HH.ru –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–º–ø–∞–Ω–∏–∏
                response = requests.get(
                    f"https://api.hh.ru/vacancies/{vacancy_id}",
                    headers={'User-Agent': 'Mozilla/5.0'},
                    timeout=10
                )
                
                if response.status_code == 200:
                    data = response.json()
                    employer = data.get('employer', {})
                    
                    # –°–∞–π—Ç –∫–æ–º–ø–∞–Ω–∏–∏
                    if employer.get('alternate_url'):
                        contacts['websites'].append(employer['alternate_url'])
                        contacts['found'] = True
                    
                    # –ï—Å–ª–∏ –µ—Å—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ, –∏—â–µ–º email
                    description = data.get('description', '')
                    import re
                    emails = re.findall(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', description)
                    if emails:
                        contacts['emails'].extend(emails)
                        contacts['found'] = True
                
                time.sleep(0.3)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                
            except Exception as e:
                pass  # –¢–∏—Ö–æ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–µ—à
        self.cache[cache_key] = contacts
        self._save_cache()
        
        return contacts if contacts['found'] else None
    
    def _get_region_id(self, city: str) -> int:
        """–ü–æ–ª—É—á–∏—Ç—å ID —Ä–µ–≥–∏–æ–Ω–∞ –¥–ª—è –≥–æ—Ä–æ–¥–∞"""
        regions = {
            '–º–æ—Å–∫–≤–∞': 1,
            '—Å–∞–Ω–∫—Ç-–ø–µ—Ç–µ—Ä–±—É—Ä–≥': 2,
            '–Ω–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫': 32,
            '–µ–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥': 48,
            '–Ω–∏–∂–Ω–∏–π –Ω–æ–≤–≥–æ—Ä–æ–¥': 43,
        }
        return regions.get(city.lower(), 1)
    
    def _extract_contacts_2gis(self, item: Dict, company_name: str) -> Dict:
        """–ò–∑–≤–ª–µ—á—å –∫–æ–Ω—Ç–∞–∫—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ 2GIS"""
        contacts = {
            'company_name': company_name,
            'found': True,
            'source': '2gis',
            'search_date': datetime.now().isoformat(),
            'phones': [],
            'emails': [],
            'websites': [],
            'address': '',
            'full_name': item.get('name', company_name)
        }
        
        # –¢–µ–ª–µ—Ñ–æ–Ω—ã –∏ –∫–æ–Ω—Ç–∞–∫—Ç—ã
        contact_groups = item.get('contact_groups', [])
        for group in contact_groups:
            for contact in group.get('contacts', []):
                if contact.get('type') == 'phone':
                    phone = contact.get('text', '')
                    if phone and phone not in contacts['phones']:
                        contacts['phones'].append(phone)
                elif contact.get('type') == 'email':
                    email = contact.get('text', '')
                    if email and email not in contacts['emails']:
                        contacts['emails'].append(email)
                elif contact.get('type') == 'website':
                    website = contact.get('url', '')
                    if website and website not in contacts['websites']:
                        contacts['websites'].append(website)
        
        # –ê–¥—Ä–µ—Å
        address_name = item.get('address_name')
        if address_name:
            contacts['address'] = address_name
        
        return contacts
    
    def process_with_limit(
        self, 
        json_file: str, 
        city: str = "–ú–æ—Å–∫–≤–∞",
        api_limit: int = 900,  # –û—Å—Ç–∞–≤–ª—è–µ–º –∑–∞–ø–∞—Å
        use_alternative: bool = True
    ) -> Tuple[List[Dict], Dict]:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ —Å —É—á–µ—Ç–æ–º –ª–∏–º–∏—Ç–∞ API
        
        Args:
            json_file: –ü—É—Ç—å –∫ JSON —Ñ–∞–π–ª—É —Å –≤–∞–∫–∞–Ω—Å–∏—è–º–∏
            city: –ì–æ—Ä–æ–¥ –¥–ª—è –ø–æ–∏—Å–∫–∞
            api_limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ API –∑–∞–ø—Ä–æ—Å–æ–≤
            use_alternative: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã
            
        Returns:
            Tuple[List[Dict], Dict]: (—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞)
        """
        print("=" * 70)
        print("üéØ –£–ú–ù–´–ô –ü–û–ò–°–ö –ö–û–ù–¢–ê–ö–¢–û–í –° –ü–†–ò–û–†–ò–¢–ò–ó–ê–¶–ò–ï–ô")
        print("=" * 70)
        print()
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏ –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–∞–Ω–∏–∏
        prioritized, stats = self.analyze_vacancies(json_file)
        
        print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–π:")
        print(f"   –í—Å–µ–≥–æ –≤–∞–∫–∞–Ω—Å–∏–π: {stats['total_vacancies']}")
        print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π: {stats['total_companies']}")
        print(f"   –ö–æ–º–ø–∞–Ω–∏–π —Å —É–∫–∞–∑–∞–Ω–Ω–æ–π –ó–ü: {stats['companies_with_salary']}")
        print()
        
        print(f"üéØ –¢–û–ü-10 –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π:")
        for i, comp in enumerate(stats['top_10_companies'][:10], 1):
            salary_mark = "üí∞" if comp['has_salary'] else "  "
            print(f"   {i}. {salary_mark} {comp['company']} ({comp['vacancies_count']} –≤–∞–∫–∞–Ω—Å–∏–π)")
        print()
        
        print(f"üîç –õ–∏–º–∏—Ç 2GIS API: {api_limit} –∑–∞–ø—Ä–æ—Å–æ–≤")
        print(f"üì¶ –í –∫–µ—à–µ —É–∂–µ –µ—Å—Ç—å: {len([k for k in self.cache.keys() if k.startswith('2gis_')])} –∫–æ–º–ø–∞–Ω–∏–π")
        print()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–∫–æ–ª—å–∫–æ –∫–æ–º–ø–∞–Ω–∏–π –±—É–¥–µ–º –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å
        companies_to_process = prioritized[:api_limit]
        
        response = input(f"–û–±—Ä–∞–±–æ—Ç–∞—Ç—å {len(companies_to_process)} –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π? (–¥–∞/–Ω–µ—Ç): ").strip().lower()
        if response not in ['–¥–∞', 'yes', 'y', '–¥']:
            print("–û—Ç–º–µ–Ω–µ–Ω–æ.")
            return [], {}
        
        print()
        print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤...")
        print()
        
        results = []
        total = len(companies_to_process)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–∞–∫–∞–Ω—Å–∏–∏ –¥–ª—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
        with open(json_file, 'r', encoding='utf-8') as f:
            vacancies = json.load(f)
        
        vacancy_links = {}
        for v in vacancies:
            company = v.get('–∫–æ–º–ø–∞–Ω–∏—è', '')
            if company and company not in vacancy_links:
                vacancy_links[company] = v.get('—Å—Å—ã–ª–∫–∞', '')
        
        for i, company_data in enumerate(companies_to_process, 1):
            company = company_data['company']
            
            print(f"[{i}/{total}] {company}...", end=' ')
            
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º 2GIS
            contacts = self.search_company_2gis(company, city)
            
            if contacts and contacts.get('found'):
                print(f"‚úì 2GIS (—Ç–µ–ª: {len(contacts.get('phones', []))}, email: {len(contacts.get('emails', []))})")
                results.append(contacts)
            elif use_alternative:
                # –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥
                alt_contacts = self.search_company_alternative(company, vacancy_links.get(company))
                if alt_contacts and alt_contacts.get('found'):
                    print(f"‚úì ALT (email: {len(alt_contacts.get('emails', []))}, web: {len(alt_contacts.get('websites', []))})")
                    results.append(alt_contacts)
                else:
                    print("‚úó –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                    if contacts:
                        results.append(contacts)
            else:
                print("‚úó –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                if contacts:
                    results.append(contacts)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–∞
            if self.api_calls_count >= api_limit:
                print()
                print(f"‚ö†Ô∏è –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç API ({api_limit} –∑–∞–ø—Ä–æ—Å–æ–≤)")
                print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–æ–º–ø–∞–Ω–∏–π: {i}/{total}")
                break
        
        print()
        print(f"‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ API –∑–∞–ø—Ä–æ—Å–æ–≤: {self.api_calls_count}/{api_limit}")
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        final_stats = {
            'total_processed': len(results),
            'found_in_2gis': len([r for r in results if r.get('source') == '2gis' and r.get('found')]),
            'found_alternative': len([r for r in results if r.get('source') == 'alternative' and r.get('found')]),
            'not_found': len([r for r in results if not r.get('found')]),
            'api_calls_used': self.api_calls_count,
            'with_phones': len([r for r in results if r.get('phones')]),
            'with_emails': len([r for r in results if r.get('emails')]),
            'with_websites': len([r for r in results if r.get('websites')])
        }
        
        return results, final_stats
    
    def export_to_csv(self, results: List[Dict], output_file: str):
        """–≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ CSV"""
        try:
            with open(output_file, 'w', encoding='utf-8-sig', newline='') as f:
                fieldnames = [
                    'company_name', 'full_name', 'found', 'source',
                    'phones', 'emails', 'websites', 'address', 'search_date'
                ]
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                
                for result in results:
                    row = {
                        'company_name': result.get('company_name', ''),
                        'full_name': result.get('full_name', result.get('company_name', '')),
                        'found': result.get('found', False),
                        'source': result.get('source', ''),
                        'phones': '; '.join(result.get('phones', [])),
                        'emails': '; '.join(result.get('emails', [])),
                        'websites': '; '.join(result.get('websites', [])),
                        'address': result.get('address', ''),
                        'search_date': result.get('search_date', '')
                    }
                    writer.writerow(row)
            
            print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è CSV: {e}")
    
    def export_to_json(self, results: List[Dict], output_file: str):
        """–≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ JSON"""
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è JSON: {e}")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    
    # ============= –ù–ê–°–¢–†–û–ô–ö–ò =============
    
    # API –∫–ª—é—á 2GIS
    API_KEY_2GIS = "75730e35-2767-46d6-b42b-548b4acae13e"
    
    # –í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª
    INPUT_FILE = "vacancies_all.json"
    
    # –ì–æ—Ä–æ–¥ –¥–ª—è –ø–æ–∏—Å–∫–∞
    CITY = "–ú–æ—Å–∫–≤–∞"
    
    # –õ–∏–º–∏—Ç API –∑–∞–ø—Ä–æ—Å–æ–≤ (–æ—Å—Ç–∞–≤–ª—è–µ–º –∑–∞–ø–∞—Å)
    API_LIMIT = 900  # –ò–∑ 1000 –¥–æ—Å—Ç—É–ø–Ω—ã—Ö
    
    # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã
    USE_ALTERNATIVE = True
    
    # –í—ã—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    OUTPUT_CSV = f"smart_contacts_{timestamp}.csv"
    OUTPUT_JSON = f"smart_contacts_{timestamp}.json"
    
    # =====================================
    
    # –°–æ–∑–¥–∞–µ–º —É–º–Ω—ã–π –ø–æ–∏—Å–∫–æ–≤–∏–∫
    finder = SmartContactsFinder(API_KEY_2GIS)
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å —É—á–µ—Ç–æ–º –ª–∏–º–∏—Ç–∞
    results, stats = finder.process_with_limit(
        INPUT_FILE, 
        CITY, 
        API_LIMIT,
        USE_ALTERNATIVE
    )
    
    if results:
        print()
        print("=" * 70)
        print("üìä –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
        print("=" * 70)
        print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–æ–º–ø–∞–Ω–∏–π: {stats['total_processed']}")
        print(f"–ù–∞–π–¥–µ–Ω–æ —á–µ—Ä–µ–∑ 2GIS: {stats['found_in_2gis']}")
        print(f"–ù–∞–π–¥–µ–Ω–æ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ: {stats['found_alternative']}")
        print(f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ: {stats['not_found']}")
        print(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ API –∑–∞–ø—Ä–æ—Å–æ–≤: {stats['api_calls_used']}/{API_LIMIT}")
        print()
        print("–ö–æ–Ω—Ç–∞–∫—Ç—ã:")
        print(f"  üìû –° —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏: {stats['with_phones']}")
        print(f"  üìß –° email: {stats['with_emails']}")
        print(f"  üåê –° —Å–∞–π—Ç–∞–º–∏: {stats['with_websites']}")
        print("=" * 70)
        print()
        
        # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º
        finder.export_to_csv(results, OUTPUT_CSV)
        finder.export_to_json(results, OUTPUT_JSON)
        
        print()
        print("‚úÖ –ì–û–¢–û–í–û!")
        print()
        print("üí° –°–æ–≤–µ—Ç: –ö–µ—à —Å–æ—Ö—Ä–∞–Ω–µ–Ω. –ü–æ–≤—Ç–æ—Ä–Ω—ã–µ –∑–∞–ø—É—Å–∫–∏ –Ω–µ –±—É–¥—É—Ç —Ç—Ä–∞—Ç–∏—Ç—å API –ª–∏–º–∏—Ç!")
    else:
        print("‚ùå –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")


if __name__ == "__main__":
    main()


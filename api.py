"""
üöÄ FastAPI –¥–ª—è HH.ru –ø–∞—Ä—Å–µ—Ä–∞
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: uvicorn api:app --reload --port 8000
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from pydantic import BaseModel, Field
from typing import Optional, List, Dict
import json
from datetime import datetime
from collections import defaultdict
import tempfile
import os

from hh_parser import HHParser
from contacts_search_engine import ContactsSearchEngine

# ================================================================
# –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø FASTAPI
# ================================================================

app = FastAPI(
    title="HH.ru Vacancy Parser API",
    description="API –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤–∞–∫–∞–Ω—Å–∏–π —Å HH.ru —Å —É–º–Ω—ã–º–∏ —Ñ–∏–ª—å—Ç—Ä–∞–º–∏ + –ø–æ–∏—Å–∫ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ –∫–æ–º–ø–∞–Ω–∏–π",
    version="2.0.0"
)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–≤–∏–∂–∫–∞ –ø–æ–∏—Å–∫–∞ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤
# API –∫–ª—é—á 2GIS - –º–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è
import os
API_KEY_2GIS = os.getenv("API_KEY_2GIS", "75730e35-2767-46d6-b42b-548b4acae13e")

contacts_engine = ContactsSearchEngine(
    api_key_2gis=API_KEY_2GIS,
    enable_2gis=True,
    enable_hh=True,
    enable_website_parsing=True
)

# CORS (–¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∏–∑ –±—Ä–∞—É–∑–µ—Ä–∞/n8n)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ================================================================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# ================================================================

def normalize_company_name(company: str) -> str:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–º–ø–∞–Ω–∏–∏ –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
    """
    if not company:
        return ""
    
    company_lower = company.lower().strip()
    
    # –£–±–∏—Ä–∞–µ–º –æ–±—â–∏–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã/—Å—É—Ñ—Ñ–∏–∫—Å—ã
    replacements = [
        ('–æ–æ–æ ', ''),
        ('–æ–∞–æ ', ''),
        ('–∑–∞–æ ', ''),
        ('–ø–∞–æ ', ''),
        ('–∏–ø ', ''),
        ('–∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π –ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å ', ''),
        (' –æ–æ–æ', ''),
        (' –æ–∞–æ', ''),
        ('"', ''),
        ("'", ''),
        ('¬´', ''),
        ('¬ª', ''),
    ]
    
    for old, new in replacements:
        company_lower = company_lower.replace(old, new)
    
    return company_lower.strip()


def calculate_vacancy_score(vacancy: Dict) -> int:
    """
    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ—Ü–µ–Ω–∫—É –≤–∞–∫–∞–Ω—Å–∏–∏ –¥–ª—è –≤—ã–±–æ—Ä–∞ –ª—É—á—à–µ–π –ø—Ä–∏ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
    """
    score = 0
    
    title = vacancy.get('–Ω–∞–∑–≤–∞–Ω–∏–µ', '').lower()
    description = vacancy.get('–æ–ø–∏—Å–∞–Ω–∏–µ', '').lower()
    
    # –ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞
    if '_pre_score' in vacancy:
        score += vacancy['_pre_score'] * 10
    else:
        score += 50
    
    # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
    priority_keywords = [
        '–≤—Ö–æ–¥—è—â–∏–µ –∑–∞—è–≤–∫–∏', '–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞—è–≤–æ–∫', 'crm', '–±–∏—Ç—Ä–∏–∫—Å',
        'amocrm', '—á–∞—Ç', '–æ–ø–µ—Ä–∞—Ç–æ—Ä', '–º–µ–Ω–µ–¥–∂–µ—Ä –ø–æ —Ä–∞–±–æ—Ç–µ —Å –∫–ª–∏–µ–Ω—Ç–∞–º–∏',
        'support', '—Ç–µ—Ö–ø–æ–¥–¥–µ—Ä–∂–∫–∞', '–∫–æ–ª–ª-—Ü–µ–Ω—Ç—Ä'
    ]
    
    # –ë–æ–Ω—É—Å—ã –∑–∞ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏
    for keyword in priority_keywords:
        if keyword in title:
            score += 20
    
    # –ë–æ–Ω—É—Å—ã –∑–∞ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏
    for keyword in priority_keywords:
        if keyword in description:
            score += 5
    
    # –ë–æ–Ω—É—Å –∑–∞ –Ω–∞–ª–∏—á–∏–µ –∑–∞—Ä–ø–ª–∞—Ç—ã
    salary = vacancy.get('–æ–ø–ª–∞—Ç–∞', '')
    if salary and salary != '–ù–µ —É–∫–∞–∑–∞–Ω–∞' and '—Ä—É–±' in salary:
        score += 10
    
    # –ë–æ–Ω—É—Å –∑–∞ –¥–ª–∏–Ω—É –æ–ø–∏—Å–∞–Ω–∏—è
    desc_length = len(description)
    if desc_length > 1000:
        score += 10
    elif desc_length > 500:
        score += 5
    
    # –ë–æ–Ω—É—Å –∑–∞ —Å–≤–µ–∂–µ—Å—Ç—å
    date_pub = vacancy.get('–¥–∞—Ç–∞_–ø—É–±–ª–∏–∫–∞—Ü–∏–∏', '')
    if '2025-12' in date_pub:
        score += 15
    elif '2025-11' in date_pub:
        score += 10
    
    return score


def deduplicate_vacancies(vacancies: List[Dict]) -> List[Dict]:
    """
    –£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –≤–∞–∫–∞–Ω—Å–∏–π –æ—Ç –æ–¥–Ω–æ–π –∫–æ–º–ø–∞–Ω–∏–∏
    –û—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ –ª—É—á—à—É—é –≤–∞–∫–∞–Ω—Å–∏—é –æ—Ç –∫–∞–∂–¥–æ–π –∫–æ–º–ø–∞–Ω–∏–∏
    """
    if not vacancies:
        return []
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∫–æ–º–ø–∞–Ω–∏—è–º
    companies = defaultdict(list)
    
    for vacancy in vacancies:
        company = vacancy.get('–∫–æ–º–ø–∞–Ω–∏—è', '')
        if not company:
            # –í–∞–∫–∞–Ω—Å–∏–∏ –±–µ–∑ –∫–æ–º–ø–∞–Ω–∏–∏ –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
            companies[f'_no_company_{id(vacancy)}'].append(vacancy)
        else:
            normalized = normalize_company_name(company)
            companies[normalized].append(vacancy)
    
    # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à—É—é –≤–∞–∫–∞–Ω—Å–∏—é –æ—Ç –∫–∞–∂–¥–æ–π –∫–æ–º–ø–∞–Ω–∏–∏
    result = []
    duplicates_removed = 0
    
    for company_key, company_vacancies in companies.items():
        if len(company_vacancies) == 1:
            result.append(company_vacancies[0])
        else:
            # –û—Ü–µ–Ω–∏–≤–∞–µ–º –≤—Å–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –∫–æ–º–ø–∞–Ω–∏–∏
            scored_vacancies = [
                (vacancy, calculate_vacancy_score(vacancy))
                for vacancy in company_vacancies
            ]
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –æ—Ü–µ–Ω–∫–µ
            scored_vacancies.sort(key=lambda x: x[1], reverse=True)
            
            # –ë–µ—Ä—ë–º –ª—É—á—à—É—é
            best_vacancy = scored_vacancies[0][0]
            best_vacancy['_duplicates_removed'] = len(company_vacancies) - 1
            
            result.append(best_vacancy)
            duplicates_removed += len(company_vacancies) - 1
    
    return result


def create_txt_file(vacancies: List[Dict], filename: str = None) -> str:
    """
    –°–æ–∑–¥–∞—ë—Ç TXT —Ñ–∞–π–ª —Å –≤–∞–∫–∞–Ω—Å–∏—è–º–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
    """
    if filename is None:
        # –°–æ–∑–¥–∞—ë–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        fd, filename = tempfile.mkstemp(suffix='.txt', prefix='vacancies_')
        os.close(fd)
    
    with open(filename, 'w', encoding='utf-8') as f:
        for i, vac in enumerate(vacancies, 1):
            f.write(f"\n{'='*80}\n")
            f.write(f"–í–ê–ö–ê–ù–°–ò–Ø #{i}\n")
            f.write(f"{'='*80}\n")
            f.write(f"–ù–∞–∑–≤–∞–Ω–∏–µ: {vac.get('–Ω–∞–∑–≤–∞–Ω–∏–µ', 'N/A')}\n")
            f.write(f"–ö–æ–º–ø–∞–Ω–∏—è: {vac.get('–∫–æ–º–ø–∞–Ω–∏—è', 'N/A')}\n")
            f.write(f"–û–ø–ª–∞—Ç–∞: {vac.get('–æ–ø–ª–∞—Ç–∞', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')}\n")
            f.write(f"–°—Å—ã–ª–∫–∞: {vac.get('—Å—Å—ã–ª–∫–∞', 'N/A')}\n")
            f.write(f"\n–û–ø–∏—Å–∞–Ω–∏–µ:\n{vac.get('–æ–ø–∏—Å–∞–Ω–∏–µ', '–ù–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è')}\n")
            f.write(f"\n{'-'*80}\n")
    
    return filename

# ================================================================
# PYDANTIC –ú–û–î–ï–õ–ò (—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∑–∞–ø—Ä–æ—Å–æ–≤/–æ—Ç–≤–µ—Ç–æ–≤)
# ================================================================

class VacancySearchRequest(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ –ø–æ–∏—Å–∫ –≤–∞–∫–∞–Ω—Å–∏–π"""
    keywords: str = Field(..., description="–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞", json_schema_extra={"example": "–≤—Ö–æ–¥—è—â–∏–µ –∑–∞—è–≤–∫–∏ CRM –æ–ø–µ—Ä–∞—Ç–æ—Ä"})
    region: int = Field(1, description="ID —Ä–µ–≥–∏–æ–Ω–∞ (1=–ú–æ—Å–∫–≤–∞, 2=–°–ü–±, 113=–†–æ—Å—Å–∏—è)", json_schema_extra={"example": 1})
    min_salary: Optional[int] = Field(None, description="–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∑–∞—Ä–ø–ª–∞—Ç–∞", json_schema_extra={"example": 50000})
    only_with_salary: bool = Field(True, description="–¢–æ–ª—å–∫–æ —Å —É–∫–∞–∑–∞–Ω–Ω–æ–π –∑–∞—Ä–ø–ª–∞—Ç–æ–π", json_schema_extra={"example": True})
    period: int = Field(7, description="–ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–Ω–µ–π (1, 3, 7, 30)", json_schema_extra={"example": 7})
    excluded_words: str = Field(
        "–Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å –±—Ä–æ–∫–µ—Ä —Å—Ç—Ä–∞—Ö–æ–≤–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç", 
        description="–°–ª–æ–≤–∞ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è (—á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª –∏–ª–∏ –∑–∞–ø—è—Ç—É—é)",
        json_schema_extra={"example": "–Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å –±—Ä–æ–∫–µ—Ä"}
    )
    sort_by: str = Field(
        "publication_time", 
        description="–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ (publication_time, relevance, salary_desc)",
        json_schema_extra={"example": "publication_time"}
    )
    limit: int = Field(20, description="–°–∫–æ–ª—å–∫–æ –í–ï–†–ù–£–¢–¨ —Å–∞–º—ã—Ö —Å–≤–µ–∂–∏—Ö –≤–∞–∫–∞–Ω—Å–∏–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 20)", json_schema_extra={"example": 20}, ge=1, le=1000)
    max_results: int = Field(10000, description="–ú–∞–∫—Å–∏–º—É–º –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è –ü–û–ò–°–ö–ê (–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 10000)", json_schema_extra={"example": 10000}, ge=1, le=10000)


class VacancyItem(BaseModel):
    """–û–¥–Ω–∞ –≤–∞–∫–∞–Ω—Å–∏—è"""
    id: str
    –Ω–∞–∑–≤–∞–Ω–∏–µ: str
    –∫–æ–º–ø–∞–Ω–∏—è: str
    –æ–ø–ª–∞—Ç–∞: str
    –æ–ø–∏—Å–∞–Ω–∏–µ: str
    —Å—Å—ã–ª–∫–∞: str
    –æ–ø—ã—Ç: str
    —Ç–∏–ø_–∑–∞–Ω—è—Ç–æ—Å—Ç–∏: str
    –¥–∞—Ç–∞_–ø—É–±–ª–∏–∫–∞—Ü–∏–∏: str


class VacancySearchResponse(BaseModel):
    """–û—Ç–≤–µ—Ç —Å –≤–∞–∫–∞–Ω—Å–∏—è–º–∏"""
    success: bool
    count: int
    message: str
    statistics: Dict
    vacancies: List[Dict]


class HealthResponse(BaseModel):
    """–û—Ç–≤–µ—Ç health check"""
    status: str
    timestamp: str
    version: str


class ContactsSearchRequest(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ –ø–æ–∏—Å–∫ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ –∫–æ–º–ø–∞–Ω–∏–∏"""
    company_name: str = Field(..., description="–ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏", example="–Ø–Ω–¥–µ–∫—Å")
    city: str = Field("–ú–æ—Å–∫–≤–∞", description="–ì–æ—Ä–æ–¥ –ø–æ–∏—Å–∫–∞", example="–ú–æ—Å–∫–≤–∞")
    vacancy_link: Optional[str] = Field(None, description="–°—Å—ã–ª–∫–∞ –Ω–∞ –≤–∞–∫–∞–Ω—Å–∏—é HH.ru (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)", example="https://hh.ru/vacancy/123456")


class ContactsSearchResponse(BaseModel):
    """–û—Ç–≤–µ—Ç —Å –∫–æ–Ω—Ç–∞–∫—Ç–∞–º–∏ –∫–æ–º–ø–∞–Ω–∏–∏"""
    success: bool
    company_name: str
    found: bool
    sources: List[str]
    contacts: Dict
    additional_info: Dict
    search_date: str
    from_cache: bool


# ================================================================
# –≠–ù–î–ü–û–ò–ù–¢–´ API
# ================================================================

@app.get("/", response_model=HealthResponse)
async def root():
    """
    üè† –ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ API
    """
    return {
        "status": "OK",
        "timestamp": datetime.now().isoformat(),
        "version": "2.0.0"
    }


@app.get("/health", response_model=HealthResponse)
async def health_check():
    """
    ‚ù§Ô∏è –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ API
    """
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "version": "2.0.0"
    }


@app.post("/api/search", response_model=VacancySearchResponse)
async def search_vacancies(request: VacancySearchRequest):
    """
    üîç –û–°–ù–û–í–ù–û–ô –≠–ù–î–ü–û–ò–ù–¢: –ü–æ–∏—Å–∫ –≤–∞–∫–∞–Ω—Å–∏–π
    
    –ò—â–µ—Ç –í–°–ï –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏, –Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ N —Å–∞–º—ã—Ö —Å–≤–µ–∂–∏—Ö.
    
    –õ–æ–≥–∏–∫–∞:
    1. Backend –∏—â–µ—Ç –º–∞–∫—Å–∏–º—É–º –≤–∞–∫–∞–Ω—Å–∏–π (–¥–æ 10000)
    2. –î–ï–î–£–ü–õ–ò–¶–ò–†–£–ï–¢ –ø–æ –∫–æ–º–ø–∞–Ω–∏—è–º (1 –∫–æ–º–ø–∞–Ω–∏—è = 1 –≤–∞–∫–∞–Ω—Å–∏—è)
    3. –°–æ—Ä—Ç–∏—Ä—É–µ—Ç –ø–æ –¥–∞—Ç–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ (—Å–≤–µ–∂–∏–µ –ø–µ—Ä–≤—ã–º–∏)
    4. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ `limit` —à—Ç—É–∫ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 20)
    
    –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç N8N –ø–æ–ª—É—á–∞—Ç—å —Ç–æ–ª—å–∫–æ —Å–∞–º—ã–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –±–µ–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤!
    """
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞
        parser = HHParser(delay=0.3)
        
        # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –ø–æ–∏—Å–∫–∞ –í–°–ï–• –≤–∞–∫–∞–Ω—Å–∏–π
        max_pages = (request.max_results + 99) // 100  # –û–∫—Ä—É–≥–ª–µ–Ω–∏–µ –≤–≤–µ—Ä—Ö
        
        # –í–ê–ñ–ù–û: –ò—â–µ–º –í–°–ï –≤–∞–∫–∞–Ω—Å–∏–∏ —Å —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–æ–π –ø–æ –¥–∞—Ç–µ!
        all_vacancies = parser.search_vacancies(
            keywords=request.keywords,
            area=request.region,
            salary=request.min_salary,
            only_with_salary=request.only_with_salary,
            period=request.period,
            excluded_text=request.excluded_words,
            order_by='publication_time',  # –í–°–ï–ì–î–ê –ø–æ –¥–∞—Ç–µ!
            max_pages=max_pages
        )
        
        # –î–ï–î–£–ü–õ–ò–¶–ò–†–£–ï–ú (—É–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∫–æ–º–ø–∞–Ω–∏–π)
        before_dedup = len(all_vacancies)
        all_vacancies = deduplicate_vacancies(all_vacancies)
        after_dedup = len(all_vacancies)
        duplicates_removed = before_dedup - after_dedup
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π, –µ—Å–ª–∏ API –≤–µ—Ä–Ω—É–ª –Ω–µ –≤ –ø–æ—Ä—è–¥–∫–µ)
        all_vacancies.sort(
            key=lambda x: x.get('–¥–∞—Ç–∞_–ø—É–±–ª–∏–∫–∞—Ü–∏–∏', ''), 
            reverse=True  # –ù–æ–≤—ã–µ –ø–µ—Ä–≤—ã–º–∏
        )
        
        # –û–ì–†–ê–ù–ò–ß–ò–í–ê–ï–ú –¥–æ limit —Å–∞–º—ã—Ö —Å–≤–µ–∂–∏—Ö
        freshest_vacancies = all_vacancies[:request.limit]
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        with_salary_count = sum(1 for v in freshest_vacancies if v['–æ–ø–ª–∞—Ç–∞'] != '–ù–µ —É–∫–∞–∑–∞–Ω–∞')
        unique_companies = len(set(v['–∫–æ–º–ø–∞–Ω–∏—è'] for v in freshest_vacancies if v.get('–∫–æ–º–ø–∞–Ω–∏—è')))
        
        statistics = {
            "total_found": before_dedup,  # –°–∫–æ–ª—å–∫–æ –í–°–ï–ì–û –Ω–∞—à–ª–∏
            "after_deduplication": after_dedup,  # –ü–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
            "duplicates_removed": duplicates_removed,  # –£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
            "returned_count": len(freshest_vacancies),  # –°–∫–æ–ª—å–∫–æ –í–ï–†–ù–£–õ–ò
            "with_salary": with_salary_count,
            "with_salary_percent": round(with_salary_count / len(freshest_vacancies) * 100, 1) if freshest_vacancies else 0,
            "unique_companies": unique_companies,
            "search_params": {
                "keywords": request.keywords,
                "region": request.region,
                "min_salary": request.min_salary,
                "period_days": request.period,
                "limit": request.limit
            }
        }
        
        return {
            "success": True,
            "count": len(freshest_vacancies),
            "message": f"–ù–∞–π–¥–µ–Ω–æ {before_dedup} –≤–∞–∫–∞–Ω—Å–∏–π, –ø–æ—Å–ª–µ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ {after_dedup}, –≤–æ–∑–≤—Ä–∞—â–µ–Ω–æ {len(freshest_vacancies)} —Å–∞–º—ã—Ö —Å–≤–µ–∂–∏—Ö",
            "statistics": statistics,
            "vacancies": freshest_vacancies  # –¢–æ–ª—å–∫–æ —Å–∞–º—ã–µ —Å–≤–µ–∂–∏–µ –±–µ–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤!
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ: {str(e)}")


@app.post("/api/search-quick")
async def search_quick(
    keywords: str,
    region: int = 1,
    limit: int = 20  # –°–∫–æ–ª—å–∫–æ –≤–µ—Ä–Ω—É—Ç—å —Å–∞–º—ã—Ö —Å–≤–µ–∂–∏—Ö
):
    """
    ‚ö° –ë–´–°–¢–†–´–ô –ü–û–ò–°–ö (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)
    
    –ú–∏–Ω–∏–º—É–º –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.
    –ò—â–µ—Ç –í–°–ï –≤–∞–∫–∞–Ω—Å–∏–∏, –¥–µ–¥—É–ø–ª–∏—Ü–∏—Ä—É–µ—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ N —Å–∞–º—ã—Ö —Å–≤–µ–∂–∏—Ö.
    """
    try:
        parser = HHParser(delay=0.3)
        
        # –ò—â–µ–º –º–∞–∫—Å–∏–º—É–º (–¥–æ 100 —Å—Ç—Ä–∞–Ω–∏—Ü = 10000 –≤–∞–∫–∞–Ω—Å–∏–π)
        all_vacancies = parser.search_vacancies(
            keywords=keywords,
            area=region,
            salary=50000,
            only_with_salary=True,
            period=7,
            excluded_text="–Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å –±—Ä–æ–∫–µ—Ä —Å—Ç—Ä–∞—Ö–æ–≤–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç",
            order_by='publication_time',  # –°–≤–µ–∂–∏–µ –ø–µ—Ä–≤—ã–º–∏!
            max_pages=100  # –ò—Å–∫–∞—Ç—å –º–∞–∫—Å–∏–º—É–º
        )
        
        # –î–ï–î–£–ü–õ–ò–¶–ò–†–£–ï–ú
        before_dedup = len(all_vacancies)
        all_vacancies = deduplicate_vacancies(all_vacancies)
        after_dedup = len(all_vacancies)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
        all_vacancies.sort(
            key=lambda x: x.get('–¥–∞—Ç–∞_–ø—É–±–ª–∏–∫–∞—Ü–∏–∏', ''), 
            reverse=True
        )
        
        # –ë–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ N —Å–∞–º—ã—Ö —Å–≤–µ–∂–∏—Ö
        freshest_vacancies = all_vacancies[:limit]
        
        return {
            "success": True,
            "total_found": before_dedup,
            "after_deduplication": after_dedup,
            "duplicates_removed": before_dedup - after_dedup,
            "returned_count": len(freshest_vacancies),
            "vacancies": freshest_vacancies
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/vacancy/{vacancy_id}")
async def get_vacancy_details(vacancy_id: str):
    """
    üìÑ –ü–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª–∏ –æ–¥–Ω–æ–π –≤–∞–∫–∞–Ω—Å–∏–∏ –ø–æ ID
    """
    try:
        parser = HHParser()
        vacancy = parser.get_vacancy_details(vacancy_id)
        
        if vacancy:
            return {
                "success": True,
                "vacancy": vacancy
            }
        else:
            raise HTTPException(status_code=404, detail="–í–∞–∫–∞–Ω—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/regions")
async def get_regions():
    """
    üåç –°–ø–∏—Å–æ–∫ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤
    """
    return {
        "regions": [
            {"id": 1, "name": "–ú–æ—Å–∫–≤–∞"},
            {"id": 2, "name": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥"},
            {"id": 3, "name": "–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥"},
            {"id": 4, "name": "–ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫"},
            {"id": 66, "name": "–ù–∏–∂–Ω–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥"},
            {"id": 88, "name": "–ö–∞–∑–∞–Ω—å"},
            {"id": 113, "name": "–†–æ—Å—Å–∏—è (–≤—Å–µ —Ä–µ–≥–∏–æ–Ω—ã)"}
        ]
    }


@app.post("/api/search-txt")
async def search_vacancies_txt(request: VacancySearchRequest):
    """
    üìÑ –ü–û–ò–°–ö –í–ê–ö–ê–ù–°–ò–ô –° –í–û–ó–í–†–ê–¢–û–ú TXT –§–ê–ô–õ–ê
    
    –†–∞–±–æ—Ç–∞–µ—Ç —Ç–∞–∫ –∂–µ –∫–∞–∫ /api/search, –Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç TXT —Ñ–∞–π–ª –≤–º–µ—Å—Ç–æ JSON.
    –ò–¥–µ–∞–ª—å–Ω–æ –¥–ª—è N8N - —Å—Ä–∞–∑—É –ø–æ–ª—É—á–∞–µ—Ç–µ —Ñ–∞–π–ª –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram!
    
    –õ–æ–≥–∏–∫–∞:
    1. –ò—â–µ—Ç –í–°–ï –≤–∞–∫–∞–Ω—Å–∏–∏
    2. –î–µ–¥—É–ø–ª–∏—Ü–∏—Ä—É–µ—Ç (1 –∫–æ–º–ø–∞–Ω–∏—è = 1 –≤–∞–∫–∞–Ω—Å–∏—è)
    3. –°–æ—Ä—Ç–∏—Ä—É–µ—Ç –ø–æ –¥–∞—Ç–µ (—Å–≤–µ–∂–∏–µ –ø–µ—Ä–≤—ã–º–∏)
    4. –ë–µ—Ä—ë—Ç —Ç–æ–ª—å–∫–æ limit —Å–∞–º—ã—Ö —Å–≤–µ–∂–∏—Ö
    5. –°–æ–∑–¥–∞—ë—Ç TXT —Ñ–∞–π–ª
    6. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ñ–∞–π–ª
    """
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞
        parser = HHParser(delay=0.3)
        
        # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü
        max_pages = (request.max_results + 99) // 100
        
        # –ò—â–µ–º –í–°–ï –≤–∞–∫–∞–Ω—Å–∏–∏
        all_vacancies = parser.search_vacancies(
            keywords=request.keywords,
            area=request.region,
            salary=request.min_salary,
            only_with_salary=request.only_with_salary,
            period=request.period,
            excluded_text=request.excluded_words,
            order_by='publication_time',
            max_pages=max_pages
        )
        
        # –î–ï–î–£–ü–õ–ò–¶–ò–†–£–ï–ú
        before_dedup = len(all_vacancies)
        all_vacancies = deduplicate_vacancies(all_vacancies)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
        all_vacancies.sort(
            key=lambda x: x.get('–¥–∞—Ç–∞_–ø—É–±–ª–∏–∫–∞—Ü–∏–∏', ''), 
            reverse=True
        )
        
        # –ë–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ limit —Å–∞–º—ã—Ö —Å–≤–µ–∂–∏—Ö
        freshest_vacancies = all_vacancies[:request.limit]
        
        # –°–æ–∑–¥–∞—ë–º TXT —Ñ–∞–π–ª
        txt_file = create_txt_file(freshest_vacancies)
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ñ–∞–π–ª
        return FileResponse(
            path=txt_file,
            filename=f"vacancies_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
            media_type="text/plain",
            background=None  # –§–∞–π–ª —É–¥–∞–ª–∏—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ—Å–ª–µ –æ—Ç–ø—Ä–∞–≤–∫–∏
        )
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞: {str(e)}")


@app.post("/api/analyze")
async def analyze_vacancies(vacancies: List[Dict]):
    """
    üìä –ê–Ω–∞–ª–∏–∑ —Å–ø–∏—Å–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–π
    
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç –º–∞—Å—Å–∏–≤ –≤–∞–∫–∞–Ω—Å–∏–π, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    """
    try:
        if not vacancies:
            return {
                "success": False,
                "message": "–ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –≤–∞–∫–∞–Ω—Å–∏–π"
            }
        
        # –ü–æ–¥—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        with_salary = sum(1 for v in vacancies if v.get('–æ–ø–ª–∞—Ç–∞') != '–ù–µ —É–∫–∞–∑–∞–Ω–∞')
        companies = [v.get('–∫–æ–º–ø–∞–Ω–∏—è') for v in vacancies if v.get('–∫–æ–º–ø–∞–Ω–∏—è')]
        unique_companies = len(set(companies))
        
        # –¢–æ–ø –∫–æ–º–ø–∞–Ω–∏–π
        from collections import Counter
        top_companies = Counter(companies).most_common(5)
        
        # –°—Ä–µ–¥–Ω—è—è –∑–∞—Ä–ø–ª–∞—Ç–∞ (–ø—Ä–∏–º–µ—Ä–Ω–∞—è)
        salaries = []
        for v in vacancies:
            salary_text = v.get('–æ–ø–ª–∞—Ç–∞', '')
            if '–æ—Ç' in salary_text:
                try:
                    salary = int(salary_text.split('–æ—Ç')[1].split()[0].replace(' ', ''))
                    salaries.append(salary)
                except:
                    pass
        
        avg_salary = sum(salaries) / len(salaries) if salaries else 0
        
        return {
            "success": True,
            "statistics": {
                "total": len(vacancies),
                "with_salary": with_salary,
                "with_salary_percent": round(with_salary / len(vacancies) * 100, 1),
                "unique_companies": unique_companies,
                "average_salary": round(avg_salary, 0) if avg_salary else None,
                "top_companies": [{"name": name, "count": count} for name, count in top_companies]
            }
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ================================================================
# –≠–ù–î–ü–û–ò–ù–¢–´ –ü–û–ò–°–ö–ê –ö–û–ù–¢–ê–ö–¢–û–í –ö–û–ú–ü–ê–ù–ò–ô
# ================================================================

@app.post("/api/contacts/search", response_model=ContactsSearchResponse)
async def search_company_contacts(request: ContactsSearchRequest):
    """
    üîç –ù–û–í–´–ô –≠–ù–î–ü–û–ò–ù–¢: –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ –∫–æ–º–ø–∞–Ω–∏–∏
    
    –ò—â–µ—Ç –∫–æ–Ω—Ç–∞–∫—Ç—ã –∫–æ–º–ø–∞–Ω–∏–∏ —á–µ—Ä–µ–∑ –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏:
    - 2GIS API (—Ç–µ–ª–µ—Ñ–æ–Ω—ã, email, –∞–¥—Ä–µ—Å–∞, —Å–∞–π—Ç—ã)
    - HH.ru (—Å–∞–π—Ç—ã –∫–æ–º–ø–∞–Ω–∏–∏, –∫–æ–Ω—Ç–∞–∫—Ç—ã –∏–∑ –≤–∞–∫–∞–Ω—Å–∏–π)
    - –ü–∞—Ä—Å–∏–Ω–≥ —Å–∞–π—Ç–æ–≤ (Telegram, WhatsApp, –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–Ω—Ç–∞–∫—Ç—ã)
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ API –ª–∏–º–∏—Ç–æ–≤.
    """
    try:
        result = contacts_engine.search_company(
            company_name=request.company_name,
            city=request.city,
            vacancy_link=request.vacancy_link
        )
        
        return {
            "success": True,
            **result
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤: {str(e)}")


@app.post("/api/contacts/search-quick")
async def search_company_contacts_quick(
    company_name: str,
    city: str = "–ú–æ—Å–∫–≤–∞"
):
    """
    ‚ö° –ë–´–°–¢–†–´–ô –ü–û–ò–°–ö –ö–û–ù–¢–ê–ö–¢–û–í (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)
    
    –ú–∏–Ω–∏–º—É–º –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è N8N –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
    """
    try:
        result = contacts_engine.search_company(
            company_name=company_name,
            city=city
        )
        
        return {
            "success": True,
            **result
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/contacts/batch")
async def search_batch_contacts(companies: List[Dict]):
    """
    üì¶ –ü–ê–ö–ï–¢–ù–´–ô –ü–û–ò–°–ö –ö–û–ù–¢–ê–ö–¢–û–í
    
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç –º–∞—Å—Å–∏–≤ –∫–æ–º–ø–∞–Ω–∏–π, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ç–∞–∫—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–π
    
    –ü—Ä–∏–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞:
    [
        {"company_name": "–Ø–Ω–¥–µ–∫—Å", "city": "–ú–æ—Å–∫–≤–∞"},
        {"company_name": "–°–±–µ—Ä", "city": "–ú–æ—Å–∫–≤–∞"}
    ]
    """
    try:
        if not companies:
            return {
                "success": False,
                "message": "–ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –∫–æ–º–ø–∞–Ω–∏–π"
            }
        
        results = []
        
        for company in companies:
            company_name = company.get('company_name')
            city = company.get('city', '–ú–æ—Å–∫–≤–∞')
            vacancy_link = company.get('vacancy_link')
            
            if not company_name:
                continue
            
            result = contacts_engine.search_company(
                company_name=company_name,
                city=city,
                vacancy_link=vacancy_link
            )
            
            results.append(result)
        
        return {
            "success": True,
            "count": len(results),
            "results": results
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/contacts/stats")
async def get_contacts_stats():
    """
    üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞–±–æ—Ç—ã –¥–≤–∏–∂–∫–∞ –ø–æ–∏—Å–∫–∞ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤
    """
    try:
        stats = contacts_engine.get_stats()
        
        return {
            "success": True,
            "stats": stats
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/contacts/clear-cache")
async def clear_contacts_cache():
    """
    üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å –∫–µ—à –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤
    """
    try:
        contacts_engine.clear_cache()
        
        return {
            "success": True,
            "message": "–ö–µ—à –æ—á–∏—â–µ–Ω"
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ================================================================
# –ó–ê–ü–£–°–ö
# ================================================================

if __name__ == "__main__":
    import uvicorn
    print("=" * 60)
    print("üöÄ –ó–∞–ø—É—Å–∫ API —Å–µ—Ä–≤–µ—Ä–∞...")
    print("=" * 60)
    print("üìç URL: http://localhost:8000")
    print("üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: http://localhost:8000/docs")
    print("=" * 60)
    uvicorn.run(app, host="0.0.0.0", port=8000)

